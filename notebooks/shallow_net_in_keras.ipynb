{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhcC_7AUcL3B"
      },
      "source": [
        "# Shallow Neural Network in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ySCLSUcL3F"
      },
      "source": [
        "Build a shallow neural network to classify MNIST digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUPqtEZcL3F"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/shallow_net_in_keras.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbyYLp2ScL3G"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Emw-i7k-cL3G"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci5uhBekcL3I"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "id": "vGqOqS3icL3I",
        "outputId": "53b32d8f-37e1-4434-93c3-17f996dae5c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jRxSsm5bcL3I",
        "outputId": "936a63d1-7d3e-4940-b343-162d4b577045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qfCau661cL3J",
        "outputId": "82cca556-9058-4001-df7d-9acdfe617a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZLgSEI-gcL3J",
        "outputId": "082f6808-cb2a-4e2e-9151-0958427acc79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "y_train[0:12]"
      ]
    },
    {
      "source": [
        "!pip install numpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "    plt.subplot(3, 4, k+1)\n",
        "    # Reshape the image data to 28x28\n",
        "    plt.imshow(X_train[k].reshape(28, 28), cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "398ugr57gcxu",
        "outputId": "2caba79c-7275-4d61-e19b-4e7aeab807db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 12 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAGuCAYAAABfpEVAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj1UlEQVR4nO3de5yN5frH8UfjOAYhEjkfNiqkQmFvIUQqbJTIoVRTCSG7XZucdlOSQ04RIeWQnb1fU1460HbKKadNJDnFVMwQNc7G/P57PNflN2vWmllrzTVrfd5/3d/XPWutO3O4eta17vvJk56enu4AAACTrsvpBQAAgIxRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYljenFwCE05EjR0SeOHGiyOPHjxd54MCBIvfv398dly9fPsirA4BrcUUNAIBhFGoAAAyjUAMAYFie9PT09JxeRChduXJF5AsXLvj92Llz54p85swZkXfv3i3yhAkT3PHf//53MTd58mSRCxUqJPK4ceNEjo+P93udyFhSUpLIdevWFfnUqVMBPV/x4sXdcXJycpbXhdxjz549Irds2VLk7du3i1yqVKlQLwlZMHPmTJGfeeYZd6zrxN69e0WuUaNG6BbmB66oAQAwjEINAIBhFGoAAAzLFfuoT58+7Y7T0tLE3I4dO0T+4osvRNY9yBkzZgRtXZUqVRJ50KBB7njWrFlirlixYiI3bdpU5ObNmwdtXdHu8OHD7rhZs2Zi7rfffhM5T548IuvvU4ECBUQ+fvy4Oz5w4ICYq1ixosgxMTH+LTgX2bdvn8j637NBgwbhXE5YbNy4UeQWLVrk0EoQiBUrVoj84osvinzddRlfp+q/CzmNK2oAAAyjUAMAYBiFGgAAw0z2qI8ePSpyvXr13LHuiYWT7mnoPrR3b/QTTzwh5kqXLi1yXFycyOy99N+lS5dE9vakHcdx2rRp44712d6Z8f6sOY7jjBkzRuQmTZq44+rVq4s5/fkH/TMQCXTf7/vvvxc5UnrU3uMldF/+hx9+CPdykAX6+3T+/PkcWkn2cUUNAIBhFGoAAAyjUAMAYJjJHnXJkiVFvvHGG91xMHvUrVq18vm6n3zyich6T63eo4vwGDJkiMj6HPXsWLVqlcj6fPcOHTq4Y/3zsW3btqCtw6pJkyaJrH+HIkVqaqo7fv3118Wc957kjsPnS6zQ91547bXXfH59/fr13bE+f6Nw4cJBW1cwcEUNAIBhFGoAAAwz+da3vgXknDlz3PGSJUvE3N133y1yp06dfD63d3vNf/7zHzGXP39+kX/99VeRJ06c6PO5ERp6i9X8+fNF9nWnVu9b1Y5z7c9H9+7dRS5fvrzItWrVEnno0KHuWP8sRvgdYx3HufYI30jlvQWipn8mkDN+/PFHkdu2bSvyyZMnfT4+ISHBHeujg63hihoAAMMo1AAAGEahBgDAMJM9au2uu+5yx3Xq1BFzuq/80ksvifzmm2+KPGrUqAwfq5UpU0ZkvU0DoZGUlCTy7bffLrK+dam+Jd1jjz3mjmfOnCnm9BYOPf/II4+IHBsbK3LZsmXdsT5S9oMPPhD5b3/7m8i6/50b/PzzzyLr702k8tXfvO+++8K4EmTkvffeEzmz44I7duwo8r333hv0NYUKV9QAABhGoQYAwDAKNQAAhuWKHrWXPsZTK168uM957xGITZs2FXO614nwSUlJccdvvPGGmNPHxnqPlHUcx6lcubLI8fHx7lh/DkHfxlLn7Dh79qzIY8eOFVkfv5kb6KMV9X9jpNBHxe7cuTPDr9VHDSM8Mvv90p8Z0d8n7+eTchuuqAEAMIxCDQCAYRRqAAAMy3U96swMGDBA5E2bNom8dOlSd/zdd9+JuVtvvTVk64J0+fJlkQcPHuyO9Vne+hzezz//XORq1aqJfOnSpWAsMdsOHjyY00vItl27dvmcD2aPPye98sorInv3j2d2dgNCx3tmwkMPPRTQY/VtLmvWrBmEFeUMrqgBADCMQg0AgGEUagAADIu4HrXuH82YMUPkFStWuGPd83j44YdFbty4scj63sbsu866n376SWTdl/basGGDyDVq1PD53Pp+5gidhg0b5vQS/l8XLlwQecuWLSLrvwuLFi3K8Ln0/veCBQtmc3Xw15o1a9zxN9984/NrO3fuLHKvXr1CsaQcwRU1AACGUagBADAs4t761kqUKCGyd2tPmzZtxNyECRN85tmzZ4vcqVMnkePi4rK4yujz3HPPiZyenu6OdYshs7e6c8qVK1dE1kcYev+bIpW+5Wgg9C009b/nqlWrRNbb3S5evOiO33nnHTGXlpYmcuHChUVu1aqVyPrtbO8Wv1q1al2zdoTG5s2bRe7Zs2eGX9u+fXuR9S1rI6lFwRU1AACGUagBADCMQg0AgGER36PWGjRo4I71EaIDBw4U+eOPPxa5T58+Iu/fv1/kIUOGuOMiRYpka52RZtu2bSKvXr1aZO9WN73Nwirdk9bb9e68885wLickYmNjRdb/jQ8++KDIf/rTn/x+7vXr14use/p588o/T/ozIN6tYd4jaB3n2lvY6qNOdc+6fPnyIntve1mqVCm9dASJ/oxDo0aN/H6sPjpYf08jCVfUAAAYRqEGAMAwCjUAAIblSY+GzZ5+On/+vMj66MqWLVuKrP/p/vrXv7pjX0cSRiPdj9Q9xLJly7rj3bt3i7mc3J+ub8fpPU7S+5kEx7m2tz5v3jyRI+H2iHPnzhX5v//9b9Ceu1u3biLrHmTlypWD9lrLli0T+YEHHhDZe0tE/fOI4PnHP/4hckJCgt+P1fvwI/mzBFxRAwBgGIUaAADDKNQAABgWdfuofdFnwzZr1kzkmJgYkXX/8t///rc73rt3r5gLZH9pNPL+21vqSU+bNk3kl156yR1XqlRJzL3yyisiR0JPWtNnL/s6i9myTz/91Oe8PjMBwZGUlCTykiVL/H5s7969RY7knrTGFTUAAIZRqAEAMIxCDQCAYVHdo9b78D755BOR9d5f3b/U7rrrLnds9R7KVvXo0SNHXlf3zN544w2Rp06dKrK3T6bvf4vI0bFjx5xeQkTS59+npKT4/PrWrVu748mTJ4dkTbkBV9QAABhGoQYAwDAKNQAAhkV8jzo5OVnkKVOmuOP3339fzB09ejSg59b7qr37avV9e6OdPhdd5zlz5rhjff5vMC1YsEDkfv36ifzbb7+J/MILL4g8fvz40CwMiALHjx8XWd/TXRs6dKg7jsRzCfzFFTUAAIZRqAEAMCzXv/WdmpoqcmJiosgjR44U+YcffsjyazVv3lxkfUu2O+64I8vPHel0K0Bnb9tBf8+eeOIJkYsUKSLyd999J/K7777rjtesWSPmDh06JHLVqlVFfuSRR0TWb30jMulWzOHDh91xlSpVwr2ciDF48GCRr1y5EtDj69SpE8zl5FpcUQMAYBiFGgAAwyjUAAAYlit61GfOnHHHR44cEXPdu3cXedu2bVl+nVatWok8YsQIkb1HhDoOW7CCKS0tzR3rHvWsWbNELlGihMg7d+70+3Xuv/9+kdu0aSPy888/7/dzIXLo3+VAe6m4ynssr76Npd6OVaBAAZGHDx8ucuHChYO8utyJK2oAAAyjUAMAYBiFGgAAw0z0qM+dOyfygAEDRF67dq07/v7777P1Wm3btnXHw4YNE3P16tUTOV++fNl6LVx1yy23iNyyZUuRv/rqqwwfq4921bem1EqXLu2O4+PjxVwojydF5Fi5cqU7btGiRQ6uJPfxnm2R2e+q99hlx5FHhuIqrqgBADCMQg0AgGEUagAADAtLj1qfr/zPf/5TZN2f9J6zG6jY2FiRR40aJfKzzz7rjqP5tmnhVrRoUZH1/sp58+a540DP1x49erTIffv2dcclS5YM6LkQnfRZ34AlXFEDAGAYhRoAAMMo1AAAGBaWHvW//vUvkfXZzZmpX7++O3700UfFXN688j/hqaeeErlgwYIBvRbCIy4uTmTvZwe8YyAUOnXqJPL06dNzaCWRp1y5cu64Xbt2Yi4xMTHcy4kIXFEDAGAYhRoAAMMo1AAAGJYnnQ2EAACYxRU1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMPy5vQCAMAfo0aNEnnYsGHuuEGDBmLuiy++ELlYsWKhWxgQYlxRAwBgGIUaAADDKNQAABiWJz09PT2nFwGEy4ULF0S+dOmSyGvXrhU5KSlJ5J49e7rjvHn5iEconTp1SuTq1auLfPLkSXecJ08eMbdt2zaRb7vttuAuDkGRkpIi8uXLl0XetGmTO37ooYfE3HXXBe86s3fv3iK/++67IsfExATttbKCK2oAAAyjUAMAYBiFGgAAw2iyIeJ4e5vjxo0TcytXrhR548aNAT23t2ft3ceL4IuNjRX5wQcfFHnOnDlhXA2y4tdffxV53rx5Is+YMUPkK1euiPzTTz+5Y92T1p9LyA79s1S8eHGRR48eLXKBAgWC9tr+4IoaAADDKNQAABhGoQYAwLCI30d96NAhkb29iOXLl4u5zZs3+3yuDz/8UOTy5cuL/OWXX7rjXr16iblKlSr5Xij8lpycLPLEiRMzzOfOnRNz+se9cuXKIpcsWVLkLVu2iHzjjTe64+3bt4u5UqVK+Vg1skv3CYcPH+6O2Udtk/47OH/+/Cw/l/7dDWaPOjN79+4VuWrVqmF7bcfhihoAANMo1AAAGEahBgDAsIjbR71u3TqRu3TpIvKxY8fcse55dOzYUeQjR46I3L17d5+v7X0+3UedMmWKz8fiqvPnz4use5PTpk0T+fTp034/t+5Vrlq1SmR91rC3J+048udHvy496uDSPwe67wz72rdvL3JmPeqyZcuKPHjwYHes91hndtb3mjVrRF66dKnPr7eMK2oAAAyjUAMAYFiue+tbv/2ht1+1a9dO5NTUVJEffvhhd6zfUtW30UtLSxO5T58+Ii9cuDDDdd5zzz0ZzsE33b5ISEjI8nPVrl1b5NWrV4tctGhRkU+cOJHl10Jw6VuQ7t692+/HbtiwQeQKFSqIXKxYsawvDH7r0KGDyN5bk/5/9NvZcXFxWX7tp59+WuRatWqJ7D2eVNN/6ytWrJjldQQDV9QAABhGoQYAwDAKNQAAhuW6HvXXX38tcuvWrX1+fdeuXUWePXu2O87sVmVr164V2VdP2nHkMaG6NwP/BXr7who1aojcvHlzdzxmzBgxp3vS2uHDhwN6bYROkSJFRB44cKDI8fHxGT5Wz+mjYfVWTISG7jln9vsXTFu3bhU5JSXF78fqzzTkzZuzpZIragAADKNQAwBgGIUaAADDckWPetKkSe5Y96n0rc6GDRsm8tChQ0XOrC/tNWDAAL+/1nEcZ9GiRe44NjY2oMfiqqlTp4p89913i9ymTRuR9TGfhQsXzvJrHz9+PMuPRWg99dRTIvvqUSP66M8U6dvfnj171u/nGjJkSFDWFCxcUQMAYBiFGgAAwyjUAAAYZrJHPX36dJG9fWndY37kkUdEfvnll0XOly9fhq+jb2m4Y8cOkfft2yeyvi2mt3fuOI5z5513Zvha8J/eP/vss8+G7bVXrlwZttdC9njP/c/slofI/fQ5/YMGDRL5u+++E/nixYt+P3fTpk1FtvbzZGs1AABAoFADAGAYhRoAAMNM9KjPnz8v8qhRo0T27pXWPWnv2d3+8N4PVZ8Drs8R1/T9Tfv27RvQayM8lixZ4o5///13Mac/Z6D34W/ZssXnc3vvd16lSpWsLhFB4O0j6u8jbDh16pTIixcvFnnZsmV+P1diYqLIgX7Pr7/+epHnzZvnjps0aSLmfH22KSdwRQ0AgGEUagAADDPx1ndaWprIx44dy/Brx48fL/KZM2dE9r7t6TjyWE/HcZz169e7Y/22qH4rRecnn3xS5Pz582e4TgTPpUuXRP75559F1sfGzp8/P8Pn8m7pcZzMt2GUL19e5Pfff9/vxwLR6JdffnHHzZo1E3P79+8P82quat++vcht27bNoZUEjr80AAAYRqEGAMAwCjUAAIaZ6FHHxMSIXKZMGZF//fVXd1yiRAkxF+hH9CtUqOCO9cf1jxw5IrK+fWL9+vUDei34z/s5haNHj4o53efS3yd9S1FvX/n+++8XcwsWLBA5NTXV57r0MbOfffaZO+7WrZuY0z/HQLTT2yF1DkSgny/RvNuxHMdx+vfv747r1auX5XWFA1fUAAAYRqEGAMAwCjUAAIaZ6FEXLFhQ5LVr14rcqFEjd5ycnCzmateuLXKPHj1Efvzxx0UuXLhwhl+re5/x8fG+lo1s0Hvnt2/f7o4bNmzo87FTp04VuUWLFiJXrVrVHZ87d07M/e9//xN548aNPl/L+/kIx3Gc3r17u2N9hKhed968Jn69IlYgt7n88ssvRe7YsWNI1gTHuemmm9zx5s2bxdzHH38scqtWrUTOztkUs2bNEnn48OFZfi5ruKIGAMAwCjUAAIZRqAEAMCxPenY2tuVC+/btc8c1atQQc7rPpW/J1qlTp9AtLMLpnvTEiRNFfumllzJ8rN6vPGPGDJH1ZxzOnj3rjh944AExt2rVKpELFCgg8tixY0X29s4dR571rXXp0kVkfQZ5XFxcho91HMe5+eabfc5D8u5bD/Q8haSkJJH1mQnIffTtkjP7ffv222/dMfuoAQBAllGoAQAwjEINAIBhUbfR09vH0D1p3efS50TDf/pc3gkTJog8dOhQkYsUKeKO58yZI+Zat24tsu5JHz58WOS+ffu649WrV4u52267TeSFCxeKXLNmTZEvXLggcr9+/dzx7NmzxdzcuXNF1p9x0PQ+7B9++MHn10N69dVX3fGYMWMCeuzMmTMzfC7kTlu3bs3pJYQMV9QAABhGoQYAwDAKNQAAhkVdj1r3KBEan376qci6J633OCYmJrrjO+64Q8zt3btX5OnTp4s8f/58kb3ne0+ePFnM6T3ZRYsWvWbtXnqfdZ06ddyx7rvrffa6D6qNHz/e5zx8834vED76TISdO3eKfMstt7jjfPnyhWwd+vz2zp07h+y1chpX1AAAGEahBgDAsKg7QtT7No0+Nk5vz/r9999Fjo2NDdm6Io0+DlPfLlJvsfK+3X369Gkxt2vXroBee9q0ae74iSeeEHOZ3Q4RuZNuae3evdvn1+vtgydOnBC5RIkSwVlYBPAeu+w4jvPaa6+JvGjRIpFPnjzpjjNrLWXG28batGmTmNO3KtV/NzT999v7fHpbpjX81QIAwDAKNQAAhlGoAQAwLOq2Zx04cCCnlxAVKlWqJLLuUetb0q1bty7D5+revbvI9913n8j6qNfrr7/eHdOTjg4NGjQQec+ePT6/np8L//Xq1UvkjRs3+vx677bD7Paovds29S1qM7u1qe5hDxo0SGTrfWkvfloBADCMQg0AgGEUagAADIu6fdS//PKLOy5btqyY032rP/74Q2T2UftP3x5y/fr1Iuue9E033eSOu3btKub0nuuYmJhgLBERZMeOHSLrY2g1/WcvOTlZZPZRX9W4cWORM+tRh4r+npUrV07kHj16iDxixAiR8+bNvR/J4ooaAADDKNQAABhGoQYAwLCo61F76fOB9d5LfcZt5cqVQ74mAIHT5zy3atVK5C1btohMj9p/R48eFXnSpEkiv/3220F7rdq1a4vs3Yetv6d9+/YV2fs5l0jDFTUAAIZRqAEAMIxCDQCAYVHdo16xYoXIrVu3FrlDhw4iT548WeQbb7wxNAsDAKMuX74s8vLly0V+8skn3XFKSoqY69Onj8gPPvigyM2aNRM5Li4uq8uMKFxRAwBgGIUaAADDKNQAABgW1T1qfR517969RV68eLHIet/exIkTRc6fP38QVwcAAFfUAACYRqEGAMCwqH7rW9NvhSckJIg8atQokZOSkkRmuxYAINi4ogYAwDAKNQAAhlGoAQAwjB41AACGcUUNAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAwyjUAAAYRqEGAMAwCjUAAIZRqAEAMIxCDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACG5c3pBQCRqnPnziKnp6eLvGTJknAuJ9c5duyYyJ9//rnICQkJ7rh58+ZirkGDBj6f+7HHHhM5JiYmK0sEwoIragAADKNQAwBgGIUaAADDIr5HnZaWJvL+/fvd8YABA8TcsmXLwrEkRKgxY8aI/Nlnn4k8cODAcC4n1/n0009F7tatm8h//PFHho/ds2ePyFOmTPH5WrqHXbNmTX+WCOQIrqgBADCMQg0AgGEUagAADIv4HvWFCxdE9vaibr75ZjGXmpoqclxcXOgWhlxv3LhxIusedf78+UVu165dyNeUm7Vo0UJk/fvnq0cdqMaNG4u8atUqkW+99dagvRaQXVxRAwBgGIUaAADDKNQAABgW8T1qX44ePSry6dOnRaZHDV/Wrl0r8sWLF0Vu3769yPfcc0/I15SbFSpUSOR3331X5EcffVTkM2fOuOMqVaqIuQMHDvh8rZMnT4qcmJgoMj3q6KL/9uvf5cWLF4s8evRon8/nPUv+rbfeyubquKIGAMA0CjUAAIZRqAEAMCyqe9T6/sDInfbt2yfysGHD3PHs2bPFnO6DBmrNmjXu+JtvvhFztWvXFnn8+PHZeq1op3v8devWFdn773/DDTeIucx61NozzzwT4OqQ2+zevVvkhQsXumN9Nvxvv/0mcp48eQJ6rRUrVgS4Ot+4ogYAwDAKNQAAhuVJj/D3f8+ePSuyry1XP/74o8h6ywdsqlevnsg7d+50x3v37hVz1apVy9Zr3XXXXe7422+/FXMbN24UWd9KEdmzYcMGkQcPHuyO161bl63nPnbsmMilS5fO1vMh/IYOHSry1q1bRQ7k7ehixYqJ3K9fP5GbNm0q8r333ity3rzB7SpzRQ0AgGEUagAADKNQAwBgWFRvz9K2b98uMj3q3KFo0aIie7dS6KMAA5WUlCSydyvYddfJ/8/Vt1RFcDVq1Ejk5cuXu+OWLVuKOf15gcy8+uqrIs+YMSPA1SHUzp07J/LIkSNFHjt2rMilSpUSuVmzZiK//vrr7lj/rde3qNU963DjihoAAMMo1AAAGEahBgDAsIjvUes+YvHixd2xPiZuz549YVkTsuedd94Ref369SLffvvt7rhSpUoBPbfuaXv7WI7jOKmpqe64devWYo7bWIbW6tWrRfb2oTdt2pSt527RokW2Ho/QGzdunMhvvvmmyCNGjBBZ76vWfefchCtqAAAMo1ADAGAYhRoAAMMivkddsGBBkb23zps3b164l4Ms+P3330VOSEgQOV++fCJ/+OGH7jg2Njag19J9runTp4tcoUIFd7xs2bKAnhu+JScni9yqVSuRd+3aJfLly5eD9tr6tRAely5dElnvX580aZI7/uijj8RcmzZtRNZn/gf7vO2cxBU1AACGUagBADCMQg0AgGGR8yY+IsYvv/wisj7HWd87WPeVa9So4fdrefvZjuM4b731ls+v9/bMEFwHDx4U+fvvvxc5mD1pTX9fhw8fHrLXwlWTJ08W2XuPccdxnPj4eHdct25dMRdJPejMcEUNAIBhFGoAAAyLnvcO/JCSkpLTS4gaV65cEfnrr792x3qrjP5afSzsqlWrRC5Tpow77tmzp5g7f/68yHPmzBE5PT1d5IEDB4r8wAMPOAiNBg0aiPzBBx+I/Pjjj4usb3uYHfp2pgiPF198UWTvLWodx3F69+7tjqPprW6NK2oAAAyjUAMAYBiFGgAAw/Kk66ZchOvVq5c71keIXn/99SKfPHkyDCuKTrqv7Os2g/pH9JZbbhF59+7dGT62efPmIu/bt0/kI0eOiOztbzuO4xw9ejTD50Z47dixQ2R9tKxXWlqayB06dBD51KlTIvft21dkfZQlQuO+++4TeeXKlSJXrFjRHScmJoo5/XcgknFFDQCAYRRqAAAMo1ADAGBY1PWoFy5c6I67desm5uhRh866detEbtasmcjeW1WWKFFCzH311VciFylSROQBAwaIvHTp0gzXoX/c9b5NnW+++WaRt2zZkuE6YYf+Pk+dOlXk559/XuRatWqJvH79endcrFixIK8ush06dMgdly9fXszFxMSIrPfCv//++yL369fPHRctWlTM7d27V+TSpUsHvNbcgitqAAAMo1ADAGAYhRoAAMOi7vDUypUrZzh38eJFkU+fPi0yvaqsGz9+vMjVqlUT2XubQb23MjP6Vnnevtfy5csDei7d23z44YdFpi+dO+h91LonrRUoUEBk/VkFXJWamipyu3btRPb2jhctWiTm/vKXv4hcqFAhkb3nXDiO7FHrffN6HfSoAQBAjqBQAwBgGIUaAADDoq5Hrffxeen+5KVLl0K9nKjRtWtXkVu3bi2y3iMZCN278u6B1dasWSNy1apVfT633luP3OHtt98O6OsHDx4scnZ+HiNdzZo1RdbnpnvvoaB70pl57733Mpzr0qWLyOXKlQvouXMzrqgBADCMQg0AgGEUagAADIu6s7696tevL/L27dtFfvXVV0UeOXJkqJcEP5w/f17khIQEkUeNGuWOa9euLeZ27twZuoXhmrOb4+PjRe7Tp487/vOf/xy019V7avUZ07qPqulz/YsXLx6UdUWi2bNni/zCCy+IfPbsWb+f69ZbbxV5165dInvPW1ixYoWY09/jSMYVNQAAhlGoAQAwLOq2Z3l17NhR5IMHD4o8bNiwcC4Hfvroo49EHj16tMg33XSTO9a310RoDR06VOS5c+eK7G0vLV68WMzdcMMNIuvjWo8cOSKy93aKL7/8spjL7K1u3S7Rt05FxrztC8e59vjVjRs3uuMlS5b4fK7k5GSRu3fvLvK4cePcccmSJQNaZyThihoAAMMo1AAAGEahBgDAsKjenqV7m/rYwRMnTojMre9yhr7daKNGjUT+8ccfRZ4wYYI7fu6550K2LlzrwIEDIut/f1+3Ha1evbrIDRs2FDkxMVFk/XPhpX9X69WrJ/KGDRtEzp8/f4bPBeQ0rqgBADCMQg0AgGEUagAADIvqfdSa3nu5adMmkXXPDOHRpEkTkfft2ydy//79RaYvnXOqVKkisr7NofdI0YceekjM6e+rzoHQe263bt2a5ecCchpX1AAAGEahBgDAMAo1AACGRfU+6goVKoickpIi8uHDh0UuVapUyNeEa82aNUvkp59+WmR9njefJbDr8uXL7njBggU+v1Z/RmTy5MkZfq2+LeWOHTtEjqZbIiLycEUNAIBhFGoAAAyjUAMAYFhU96j1flu911KfS1ysWLGQrwkAAC+uqAEAMIxCDQCAYRRqAAAMi+oeNQAA1nFFDQCAYRRqAAAMo1ADAGAYhRoAAMMo1AAAGEahBgDAMAo1AACGUagBADCMQg0AgGEUagAADKNQAwBgGIUaAADDKNQAABhGoQYAwDAKNQAAhlGoAQAwjEINAIBhFGoAAAyjUAMAYBiFGgAAw/4Pl0XiurxH+dsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Grayscale images\n",
        "This code creates a plot displaying 12 grayscale images arranged in a 3x4 grid using matplotlib, typically used in machine learning or computer vision tasks where you want to visualize a subset of training data.\n",
        "\n",
        "----------------\n",
        "Here's a breakdown of what each line does:\n",
        "\n",
        "plt.figure(figsize=(5,5)):\n",
        "\n",
        "##Initializes a new figure with a size of 5x5 inches.\n",
        "\n",
        "This is the canvas on which the images will be plotted.\n",
        "\n",
        "for k in range(12): Loops over the first 12 images in X_train (which presumably contains image data).\n",
        "\n",
        "##plt.subplot(3, 4, k+1):\n",
        "\n",
        "Creates a subplot in a 3-row, 4-column grid. k+1 is used to specify the position of the current subplot (from 1 to 12).\n",
        "\n",
        "##plt.imshow(X_train[k], cmap='Greys'):\n",
        "Displays the k-th image from the X_train dataset.\n",
        "\n",
        "The cmap='Greys' argument ensures the image is displayed in grayscale.\n",
        "\n",
        "##plt.axis('off'):\n",
        "Hides the axis for each subplot, making the plot cleaner by removing ticks and labels.\n",
        "\n",
        "##plt.tight_layout():\n",
        "Automatically adjusts the spacing between subplots to prevent overlap.\n",
        "\n",
        "##plt.show():\n",
        "Displays the figure with the 12 images.\n",
        "\n",
        "In summary, the code displays 12 grayscale images from the X_train dataset, organized in a 3x4 grid."
      ],
      "metadata": {
        "id": "U6oiiFmvfRtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BmmdbAP1dLiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3Kam3IkgcL3K",
        "outputId": "1973fc20-ba92-4a2e-b7c6-d73f63144e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ocw2wxp-cL3L",
        "outputId": "dcac1959-8b5a-4f69-d125-a32b0a08ddc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aIAsIPWwcL3M",
        "outputId": "98182081-36e3-4c1a-d78e-621ac3839796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7cc8c5229ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(X_valid[0], cmap='Greys')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pl-tw07-cL3M",
        "outputId": "dde7225a-5453-47dc-91f0-b018f82544fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-8758c71e-9fbf-4822-b7c6-5e941788de3d\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-8758c71e-9fbf-4822-b7c6-5e941788de3d button').onclick = (e) => {\n",
              "        document.querySelector('#id-8758c71e-9fbf-4822-b7c6-5e941788de3d').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-8758c71e-9fbf-4822-b7c6-5e941788de3d button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xpRGWm-2cL3M",
        "outputId": "5ade0bd7-d7d9-44d4-96c7-8cd403b0efb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y_valid[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43eK1mW6cL3N"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uigAFZhOcL3N"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(10000, 784).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DuhK0-6CcL3N"
      },
      "outputs": [],
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0QKyATVncL3N",
        "outputId": "f8e169f5-3929-41a4-f3b6-baf7f977ba58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_valid[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DekOr5THcL3N"
      },
      "outputs": [],
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-wqyG4lcL3N",
        "outputId": "1a8e9333-8228-4fd6-cbd9-d205a8eb02b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_valid[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPxp6jdVcL3N"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9eNK9a9cL3O"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9GOkByvcL3O",
        "outputId": "9876fde4-2416-42e9-975b-0fb49219f7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYjc9vpncL3O",
        "outputId": "6152dc85-0c1b-4343-f57d-3610341ff71f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50176"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(64*784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y--zzkxwcL3O",
        "outputId": "25b2b890-e365-4559-d966-6514d193b2b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(64*784)+64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FxVZ9S8cL3O",
        "outputId": "e66d7810-be27-4627-e555-f84539244e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(10*64)+10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7H1PF8TcL3O"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXMpFaTZcL3P"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLcGOGA2cL3P"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNbObl4McL3P",
        "outputId": "f013384f-9bb1-4635-e961-2dbc8167e932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 1s 12us/step - loss: 0.0923 - acc: 0.0943 - val_loss: 0.0919 - val_acc: 0.1010\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0916 - acc: 0.0979 - val_loss: 0.0912 - val_acc: 0.1075\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0910 - acc: 0.1045 - val_loss: 0.0907 - val_acc: 0.1165\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0905 - acc: 0.1157 - val_loss: 0.0902 - val_acc: 0.1330\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0900 - acc: 0.1386 - val_loss: 0.0898 - val_acc: 0.1653\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0896 - acc: 0.1754 - val_loss: 0.0894 - val_acc: 0.2143\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0892 - acc: 0.2260 - val_loss: 0.0890 - val_acc: 0.2720\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0889 - acc: 0.2820 - val_loss: 0.0887 - val_acc: 0.3124\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0885 - acc: 0.3227 - val_loss: 0.0883 - val_acc: 0.3474\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0882 - acc: 0.3527 - val_loss: 0.0880 - val_acc: 0.3649\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0878 - acc: 0.3717 - val_loss: 0.0876 - val_acc: 0.3791\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0875 - acc: 0.3777 - val_loss: 0.0873 - val_acc: 0.3815\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0871 - acc: 0.3794 - val_loss: 0.0869 - val_acc: 0.3820\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0868 - acc: 0.3786 - val_loss: 0.0866 - val_acc: 0.3811\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0864 - acc: 0.3783 - val_loss: 0.0862 - val_acc: 0.3789\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0861 - acc: 0.3787 - val_loss: 0.0858 - val_acc: 0.3799\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0857 - acc: 0.3801 - val_loss: 0.0854 - val_acc: 0.3794\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0853 - acc: 0.3799 - val_loss: 0.0851 - val_acc: 0.3815\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0849 - acc: 0.3815 - val_loss: 0.0847 - val_acc: 0.3818\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0845 - acc: 0.3816 - val_loss: 0.0843 - val_acc: 0.3836\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0842 - acc: 0.3845 - val_loss: 0.0839 - val_acc: 0.3861\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0838 - acc: 0.3867 - val_loss: 0.0835 - val_acc: 0.3882\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0833 - acc: 0.3893 - val_loss: 0.0830 - val_acc: 0.3917\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0829 - acc: 0.3913 - val_loss: 0.0826 - val_acc: 0.3956\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0825 - acc: 0.3951 - val_loss: 0.0822 - val_acc: 0.4001\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0821 - acc: 0.3993 - val_loss: 0.0817 - val_acc: 0.4034\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0816 - acc: 0.4021 - val_loss: 0.0813 - val_acc: 0.4075\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0812 - acc: 0.4078 - val_loss: 0.0808 - val_acc: 0.4118\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0808 - acc: 0.4130 - val_loss: 0.0804 - val_acc: 0.4172\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0803 - acc: 0.4172 - val_loss: 0.0799 - val_acc: 0.4219\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0798 - acc: 0.4243 - val_loss: 0.0795 - val_acc: 0.4271\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0794 - acc: 0.4297 - val_loss: 0.0790 - val_acc: 0.4309\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0789 - acc: 0.4348 - val_loss: 0.0785 - val_acc: 0.4365\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0784 - acc: 0.4402 - val_loss: 0.0780 - val_acc: 0.4418\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0780 - acc: 0.4466 - val_loss: 0.0776 - val_acc: 0.4464\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0775 - acc: 0.4527 - val_loss: 0.0771 - val_acc: 0.4521\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0770 - acc: 0.4583 - val_loss: 0.0766 - val_acc: 0.4592\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0765 - acc: 0.4657 - val_loss: 0.0761 - val_acc: 0.4657\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0761 - acc: 0.4716 - val_loss: 0.0756 - val_acc: 0.4722\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0756 - acc: 0.4778 - val_loss: 0.0751 - val_acc: 0.4782\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0751 - acc: 0.4840 - val_loss: 0.0746 - val_acc: 0.4849\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0746 - acc: 0.4901 - val_loss: 0.0741 - val_acc: 0.4909\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0741 - acc: 0.4960 - val_loss: 0.0736 - val_acc: 0.4966\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0736 - acc: 0.5030 - val_loss: 0.0732 - val_acc: 0.5034\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0731 - acc: 0.5084 - val_loss: 0.0727 - val_acc: 0.5094\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0727 - acc: 0.5138 - val_loss: 0.0722 - val_acc: 0.5155\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0722 - acc: 0.5195 - val_loss: 0.0717 - val_acc: 0.5193\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0717 - acc: 0.5243 - val_loss: 0.0712 - val_acc: 0.5251\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0712 - acc: 0.5292 - val_loss: 0.0707 - val_acc: 0.5310\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0707 - acc: 0.5343 - val_loss: 0.0702 - val_acc: 0.5364\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0702 - acc: 0.5395 - val_loss: 0.0697 - val_acc: 0.5420\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0698 - acc: 0.5440 - val_loss: 0.0693 - val_acc: 0.5467\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0693 - acc: 0.5488 - val_loss: 0.0688 - val_acc: 0.5521\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0688 - acc: 0.5528 - val_loss: 0.0683 - val_acc: 0.5568\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0683 - acc: 0.5574 - val_loss: 0.0678 - val_acc: 0.5616\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0679 - acc: 0.5615 - val_loss: 0.0673 - val_acc: 0.5668\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0674 - acc: 0.5663 - val_loss: 0.0669 - val_acc: 0.5706\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0669 - acc: 0.5705 - val_loss: 0.0664 - val_acc: 0.5742\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0665 - acc: 0.5743 - val_loss: 0.0659 - val_acc: 0.5778\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0660 - acc: 0.5790 - val_loss: 0.0655 - val_acc: 0.5824\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0655 - acc: 0.5830 - val_loss: 0.0650 - val_acc: 0.5888\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0651 - acc: 0.5870 - val_loss: 0.0645 - val_acc: 0.5937\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0646 - acc: 0.5910 - val_loss: 0.0641 - val_acc: 0.5967\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0642 - acc: 0.5957 - val_loss: 0.0636 - val_acc: 0.6013\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0637 - acc: 0.5997 - val_loss: 0.0632 - val_acc: 0.6067\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0633 - acc: 0.6039 - val_loss: 0.0627 - val_acc: 0.6120\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0628 - acc: 0.6085 - val_loss: 0.0623 - val_acc: 0.6174\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0624 - acc: 0.6129 - val_loss: 0.0618 - val_acc: 0.6216\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0619 - acc: 0.6171 - val_loss: 0.0614 - val_acc: 0.6249\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0615 - acc: 0.6213 - val_loss: 0.0609 - val_acc: 0.6301\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0610 - acc: 0.6256 - val_loss: 0.0605 - val_acc: 0.6346\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0606 - acc: 0.6294 - val_loss: 0.0600 - val_acc: 0.6392\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0602 - acc: 0.6340 - val_loss: 0.0596 - val_acc: 0.6437\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0598 - acc: 0.6378 - val_loss: 0.0592 - val_acc: 0.6475\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0593 - acc: 0.6416 - val_loss: 0.0587 - val_acc: 0.6505\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0589 - acc: 0.6460 - val_loss: 0.0583 - val_acc: 0.6544\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0585 - acc: 0.6499 - val_loss: 0.0579 - val_acc: 0.6592\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0581 - acc: 0.6537 - val_loss: 0.0575 - val_acc: 0.6635\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0577 - acc: 0.6572 - val_loss: 0.0570 - val_acc: 0.6664\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0572 - acc: 0.6612 - val_loss: 0.0566 - val_acc: 0.6698\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0568 - acc: 0.6647 - val_loss: 0.0562 - val_acc: 0.6731\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0564 - acc: 0.6683 - val_loss: 0.0558 - val_acc: 0.6762\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0560 - acc: 0.6714 - val_loss: 0.0554 - val_acc: 0.6795\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0556 - acc: 0.6748 - val_loss: 0.0550 - val_acc: 0.6833\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0552 - acc: 0.6794 - val_loss: 0.0546 - val_acc: 0.6868\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0548 - acc: 0.6826 - val_loss: 0.0542 - val_acc: 0.6903\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0545 - acc: 0.6855 - val_loss: 0.0538 - val_acc: 0.6942\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0541 - acc: 0.6890 - val_loss: 0.0534 - val_acc: 0.6986\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0537 - acc: 0.6922 - val_loss: 0.0530 - val_acc: 0.7018\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0533 - acc: 0.6948 - val_loss: 0.0526 - val_acc: 0.7049\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0529 - acc: 0.6976 - val_loss: 0.0522 - val_acc: 0.7083\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0526 - acc: 0.7001 - val_loss: 0.0519 - val_acc: 0.7115\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0522 - acc: 0.7031 - val_loss: 0.0515 - val_acc: 0.7142\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0518 - acc: 0.7065 - val_loss: 0.0511 - val_acc: 0.7174\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0515 - acc: 0.7095 - val_loss: 0.0507 - val_acc: 0.7206\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0511 - acc: 0.7121 - val_loss: 0.0504 - val_acc: 0.7227\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0507 - acc: 0.7151 - val_loss: 0.0500 - val_acc: 0.7259\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0504 - acc: 0.7179 - val_loss: 0.0497 - val_acc: 0.7287\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0500 - acc: 0.7209 - val_loss: 0.0493 - val_acc: 0.7310\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0497 - acc: 0.7236 - val_loss: 0.0489 - val_acc: 0.7340\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0493 - acc: 0.7262 - val_loss: 0.0486 - val_acc: 0.7370\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0490 - acc: 0.7286 - val_loss: 0.0483 - val_acc: 0.7397\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0487 - acc: 0.7313 - val_loss: 0.0479 - val_acc: 0.7418\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0483 - acc: 0.7334 - val_loss: 0.0476 - val_acc: 0.7445\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0480 - acc: 0.7360 - val_loss: 0.0472 - val_acc: 0.7464\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0477 - acc: 0.7385 - val_loss: 0.0469 - val_acc: 0.7499\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0474 - acc: 0.7408 - val_loss: 0.0466 - val_acc: 0.7514\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0471 - acc: 0.7435 - val_loss: 0.0463 - val_acc: 0.7533\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0468 - acc: 0.7451 - val_loss: 0.0460 - val_acc: 0.7564\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0465 - acc: 0.7468 - val_loss: 0.0457 - val_acc: 0.7589\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0462 - acc: 0.7494 - val_loss: 0.0453 - val_acc: 0.7603\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0459 - acc: 0.7510 - val_loss: 0.0450 - val_acc: 0.7615\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0456 - acc: 0.7531 - val_loss: 0.0447 - val_acc: 0.7631\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0453 - acc: 0.7549 - val_loss: 0.0444 - val_acc: 0.7649\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0450 - acc: 0.7562 - val_loss: 0.0442 - val_acc: 0.7665\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0447 - acc: 0.7582 - val_loss: 0.0439 - val_acc: 0.7684\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0444 - acc: 0.7595 - val_loss: 0.0436 - val_acc: 0.7693\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0442 - acc: 0.7608 - val_loss: 0.0433 - val_acc: 0.7708\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0439 - acc: 0.7624 - val_loss: 0.0430 - val_acc: 0.7716\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0436 - acc: 0.7636 - val_loss: 0.0428 - val_acc: 0.7732\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0434 - acc: 0.7651 - val_loss: 0.0425 - val_acc: 0.7743\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0431 - acc: 0.7665 - val_loss: 0.0422 - val_acc: 0.7758\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0428 - acc: 0.7677 - val_loss: 0.0420 - val_acc: 0.7777\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0426 - acc: 0.7685 - val_loss: 0.0417 - val_acc: 0.7791\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0423 - acc: 0.7694 - val_loss: 0.0415 - val_acc: 0.7803\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0421 - acc: 0.7707 - val_loss: 0.0412 - val_acc: 0.7810\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0419 - acc: 0.7715 - val_loss: 0.0410 - val_acc: 0.7815\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0416 - acc: 0.7723 - val_loss: 0.0407 - val_acc: 0.7829\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0414 - acc: 0.7729 - val_loss: 0.0405 - val_acc: 0.7832\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0412 - acc: 0.7737 - val_loss: 0.0403 - val_acc: 0.7843\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0409 - acc: 0.7747 - val_loss: 0.0400 - val_acc: 0.7850\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0407 - acc: 0.7753 - val_loss: 0.0398 - val_acc: 0.7863\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0405 - acc: 0.7760 - val_loss: 0.0396 - val_acc: 0.7865\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0403 - acc: 0.7767 - val_loss: 0.0394 - val_acc: 0.7875\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0400 - acc: 0.7774 - val_loss: 0.0391 - val_acc: 0.7881\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0398 - acc: 0.7780 - val_loss: 0.0389 - val_acc: 0.7890\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0396 - acc: 0.7788 - val_loss: 0.0387 - val_acc: 0.7897\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0394 - acc: 0.7793 - val_loss: 0.0385 - val_acc: 0.7904\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0392 - acc: 0.7798 - val_loss: 0.0383 - val_acc: 0.7908\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0390 - acc: 0.7806 - val_loss: 0.0381 - val_acc: 0.7920\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0388 - acc: 0.7813 - val_loss: 0.0379 - val_acc: 0.7923\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0386 - acc: 0.7818 - val_loss: 0.0377 - val_acc: 0.7929\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 1s 11us/step - loss: 0.0384 - acc: 0.7824 - val_loss: 0.0375 - val_acc: 0.7936\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0382 - acc: 0.7828 - val_loss: 0.0373 - val_acc: 0.7942\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.0380 - acc: 0.7836 - val_loss: 0.0371 - val_acc: 0.7944\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0378 - acc: 0.7841 - val_loss: 0.0369 - val_acc: 0.7946\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0377 - acc: 0.7847 - val_loss: 0.0367 - val_acc: 0.7948\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0375 - acc: 0.7854 - val_loss: 0.0365 - val_acc: 0.7954\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0373 - acc: 0.7859 - val_loss: 0.0363 - val_acc: 0.7960\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0371 - acc: 0.7865 - val_loss: 0.0362 - val_acc: 0.7966\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0369 - acc: 0.7868 - val_loss: 0.0360 - val_acc: 0.7975\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0367 - acc: 0.7872 - val_loss: 0.0358 - val_acc: 0.7982\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0366 - acc: 0.7879 - val_loss: 0.0356 - val_acc: 0.7990\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0364 - acc: 0.7887 - val_loss: 0.0354 - val_acc: 0.7995\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0362 - acc: 0.7894 - val_loss: 0.0353 - val_acc: 0.8004\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0360 - acc: 0.7900 - val_loss: 0.0351 - val_acc: 0.8006\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0359 - acc: 0.7906 - val_loss: 0.0349 - val_acc: 0.8019\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0357 - acc: 0.7913 - val_loss: 0.0347 - val_acc: 0.8027\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0355 - acc: 0.7921 - val_loss: 0.0346 - val_acc: 0.8035\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0354 - acc: 0.7929 - val_loss: 0.0344 - val_acc: 0.8044\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0352 - acc: 0.7937 - val_loss: 0.0342 - val_acc: 0.8057\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0350 - acc: 0.7947 - val_loss: 0.0341 - val_acc: 0.8070\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0349 - acc: 0.7959 - val_loss: 0.0339 - val_acc: 0.8083\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0347 - acc: 0.7970 - val_loss: 0.0337 - val_acc: 0.8094\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0345 - acc: 0.7982 - val_loss: 0.0336 - val_acc: 0.8106\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0344 - acc: 0.7993 - val_loss: 0.0334 - val_acc: 0.8121\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0342 - acc: 0.8008 - val_loss: 0.0333 - val_acc: 0.8135\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0341 - acc: 0.8021 - val_loss: 0.0331 - val_acc: 0.8149\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0339 - acc: 0.8035 - val_loss: 0.0329 - val_acc: 0.8168\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0337 - acc: 0.8050 - val_loss: 0.0328 - val_acc: 0.8187\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0336 - acc: 0.8066 - val_loss: 0.0326 - val_acc: 0.8199\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0334 - acc: 0.8079 - val_loss: 0.0325 - val_acc: 0.8205\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0333 - acc: 0.8092 - val_loss: 0.0323 - val_acc: 0.8221\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0331 - acc: 0.8111 - val_loss: 0.0322 - val_acc: 0.8240\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0330 - acc: 0.8127 - val_loss: 0.0320 - val_acc: 0.8247\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0328 - acc: 0.8141 - val_loss: 0.0319 - val_acc: 0.8269\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0327 - acc: 0.8160 - val_loss: 0.0317 - val_acc: 0.8279\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0325 - acc: 0.8174 - val_loss: 0.0316 - val_acc: 0.8292\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0324 - acc: 0.8185 - val_loss: 0.0314 - val_acc: 0.8303\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0323 - acc: 0.8201 - val_loss: 0.0313 - val_acc: 0.8322\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0321 - acc: 0.8217 - val_loss: 0.0311 - val_acc: 0.8341\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0320 - acc: 0.8230 - val_loss: 0.0310 - val_acc: 0.8358\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0318 - acc: 0.8245 - val_loss: 0.0309 - val_acc: 0.8376\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0317 - acc: 0.8256 - val_loss: 0.0307 - val_acc: 0.8382\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0316 - acc: 0.8275 - val_loss: 0.0306 - val_acc: 0.8396\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0314 - acc: 0.8287 - val_loss: 0.0304 - val_acc: 0.8407\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0313 - acc: 0.8301 - val_loss: 0.0303 - val_acc: 0.8427\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0311 - acc: 0.8310 - val_loss: 0.0302 - val_acc: 0.8436\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0310 - acc: 0.8323 - val_loss: 0.0300 - val_acc: 0.8454\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0309 - acc: 0.8338 - val_loss: 0.0299 - val_acc: 0.8469\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0307 - acc: 0.8348 - val_loss: 0.0298 - val_acc: 0.8483\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0306 - acc: 0.8360 - val_loss: 0.0296 - val_acc: 0.8492\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0305 - acc: 0.8371 - val_loss: 0.0295 - val_acc: 0.8498\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0304 - acc: 0.8383 - val_loss: 0.0294 - val_acc: 0.8509\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0302 - acc: 0.8396 - val_loss: 0.0292 - val_acc: 0.8518\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0301 - acc: 0.8405 - val_loss: 0.0291 - val_acc: 0.8525\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0300 - acc: 0.8414 - val_loss: 0.0290 - val_acc: 0.8532\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0299 - acc: 0.8425 - val_loss: 0.0289 - val_acc: 0.8544\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0297 - acc: 0.8437 - val_loss: 0.0287 - val_acc: 0.8548\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.0296 - acc: 0.8446 - val_loss: 0.0286 - val_acc: 0.8560\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ccd479b38>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khtg5FCicL3P",
        "outputId": "dd72f41b-ca55-4a29-f00e-f7045f588609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 11us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.02861827013194561, 0.856]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzIE5W8AcL3P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}